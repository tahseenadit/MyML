{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleRNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-9KOXW4TQLn",
        "outputId": "ec834201-6072-4669-9371-385fae2a292a"
      },
      "source": [
        "import statistics\r\n",
        "\r\n",
        "inputs = [1,2,3,4]\r\n",
        "\r\n",
        "initial_prediction = 0 # Guessed\r\n",
        "initial_weight = 0.5\r\n",
        "initial_bias = 0.1\r\n",
        "initial_loss = inputs[0] - initial_prediction\r\n",
        "\r\n",
        "w = initial_weight\r\n",
        "b = initial_bias\r\n",
        "output = initial_prediction\r\n",
        "losses = []\r\n",
        "losses.append(initial_loss)\r\n",
        "\r\n",
        "dw = 0.001\r\n",
        "avg_loss = 10000\r\n",
        "\r\n",
        "def hidden_node_function(input,prediction,weight,bias):\r\n",
        "  output_from_hidden_layer_neuron = weight*prediction + weight*input + bias\r\n",
        "  return output_from_hidden_layer_neuron\r\n",
        "\r\n",
        "def activation_function(output_from_hidden_layer_neuron):\r\n",
        "  output_from_hidden_layer_neuron_activation_function = output_from_hidden_layer_neuron\r\n",
        "  return output_from_hidden_layer_neuron_activation_function\r\n",
        "\r\n",
        "epochs = 0\r\n",
        "\r\n",
        "\r\n",
        "for i in range(len(inputs)-1):\r\n",
        "    x = inputs[i]\r\n",
        "    output_from_hidden_layer_neuron = hidden_node_function(x,output,w,b)\r\n",
        "    output_from_hidden_layer_neuron_activation_function = activation_function(output_from_hidden_layer_neuron)\r\n",
        "    output = output_from_hidden_layer_neuron_activation_function\r\n",
        "    loss = inputs[i+1] - output\r\n",
        "    losses.append(loss)\r\n",
        "new_avg_loss = statistics.mean(losses)\r\n",
        "w = w + dw \r\n",
        "avg_loss = new_avg_loss\r\n",
        "epochs = epochs + 1\r\n",
        "print(\"Epoch : \", epochs ,\", Avg loss : \",avg_loss)\r\n",
        "\r\n",
        "\r\n",
        "while avg_loss > 0.1:\r\n",
        "\r\n",
        "  for i in range(len(inputs)-1):\r\n",
        "    x = inputs[i]\r\n",
        "    output_from_hidden_layer_neuron = hidden_node_function(x,output,w,b)\r\n",
        "    output_from_hidden_layer_neuron_activation_function = activation_function(output_from_hidden_layer_neuron)\r\n",
        "    output = output_from_hidden_layer_neuron_activation_function\r\n",
        "    loss = inputs[i+1] - output\r\n",
        "    losses.append(loss)\r\n",
        "  new_avg_loss = statistics.mean(losses)\r\n",
        "\r\n",
        "  if new_avg_loss > 0.1:\r\n",
        "    if new_avg_loss < avg_loss:\r\n",
        "      w = w + dw\r\n",
        "    else:\r\n",
        "      w = w - dw\r\n",
        "\r\n",
        "  avg_loss = new_avg_loss\r\n",
        "  epochs = epochs + 1\r\n",
        "  print(\"Epoch : \", epochs ,\", Avg loss : \",avg_loss)\r\n",
        "\r\n",
        "### Prediction\r\n",
        "\r\n",
        "x = inputs[-1]\r\n",
        "output_from_hidden_layer_neuron = hidden_node_function(x,output,w,b)\r\n",
        "output_from_hidden_layer_neuron_activation_function = activation_function(output_from_hidden_layer_neuron)\r\n",
        "output = output_from_hidden_layer_neuron_activation_function\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Original output: \", 5)\r\n",
        "print(\"Predicted output: \", output)\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  1 , Avg loss :  1.4249999999999998\n",
            "Epoch :  2 , Avg loss :  1.1958735209571427\n",
            "Epoch :  3 , Avg loss :  1.0765912468187357\n",
            "Epoch :  4 , Avg loss :  1.0079759063210478\n",
            "Epoch :  5 , Avg loss :  0.9632477260274447\n",
            "Epoch :  6 , Avg loss :  0.9312705437130628\n",
            "Epoch :  7 , Avg loss :  0.9068436232903434\n",
            "Epoch :  8 , Avg loss :  0.887247002788827\n",
            "Epoch :  9 , Avg loss :  0.8709246168797543\n",
            "Epoch :  10 , Avg loss :  0.8569225205849094\n",
            "Epoch :  11 , Avg loss :  0.8446234120824141\n",
            "Epoch :  12 , Avg loss :  0.8336101751609534\n",
            "Epoch :  13 , Avg loss :  0.8235908118400225\n",
            "Epoch :  14 , Avg loss :  0.8143547966390166\n",
            "Epoch :  15 , Avg loss :  0.80574650937637\n",
            "Epoch :  16 , Avg loss :  0.797648427318672\n",
            "Epoch :  17 , Avg loss :  0.7899701354273461\n",
            "Epoch :  18 , Avg loss :  0.7826409332503944\n",
            "Epoch :  19 , Avg loss :  0.7756047362260101\n",
            "Epoch :  20 , Avg loss :  0.7688164815185955\n",
            "Epoch :  21 , Avg loss :  0.7622395447124877\n",
            "Epoch :  22 , Avg loss :  0.7558438505273826\n",
            "Epoch :  23 , Avg loss :  0.7496044693489379\n",
            "Epoch :  24 , Avg loss :  0.7435005598194929\n",
            "Epoch :  25 , Avg loss :  0.7375145618670211\n",
            "Epoch :  26 , Avg loss :  0.7316315736001174\n",
            "Epoch :  27 , Avg loss :  0.7258388649813671\n",
            "Epoch :  28 , Avg loss :  0.7201254944867819\n",
            "Epoch :  29 , Avg loss :  0.7144820041750725\n",
            "Epoch :  30 , Avg loss :  0.7089001750721721\n",
            "Epoch :  31 , Avg loss :  0.7033728293963171\n",
            "Epoch :  32 , Avg loss :  0.6978936694829383\n",
            "Epoch :  33 , Avg loss :  0.6924571457023938\n",
            "Epoch :  34 , Avg loss :  0.6870583474593717\n",
            "Epoch :  35 , Avg loss :  0.6816929127011732\n",
            "Epoch :  36 , Avg loss :  0.6763569523689353\n",
            "Epoch :  37 , Avg loss :  0.6710469869899842\n",
            "Epoch :  38 , Avg loss :  0.6657598931942347\n",
            "Epoch :  39 , Avg loss :  0.6604928583884857\n",
            "Epoch :  40 , Avg loss :  0.6552433421727691\n",
            "Epoch :  41 , Avg loss :  0.6500090433569461\n",
            "Epoch :  42 , Avg loss :  0.6447878716515166\n",
            "Epoch :  43 , Avg loss :  0.6395779232775718\n",
            "Epoch :  44 , Avg loss :  0.6343774598770662\n",
            "Epoch :  45 , Avg loss :  0.6291848902137981\n",
            "Epoch :  46 , Avg loss :  0.6239987542434691\n",
            "Epoch :  47 , Avg loss :  0.6188177092024613\n",
            "Epoch :  48 , Avg loss :  0.6136405174229578\n",
            "Epoch :  49 , Avg loss :  0.6084660356294447\n",
            "Epoch :  50 , Avg loss :  0.6032932055105685\n",
            "Epoch :  51 , Avg loss :  0.5981210453924286\n",
            "Epoch :  52 , Avg loss :  0.5929486428659723\n",
            "Epoch :  53 , Avg loss :  0.587775148243259\n",
            "Epoch :  54 , Avg loss :  0.5825997687358007\n",
            "Epoch :  55 , Avg loss :  0.5774217632636225\n",
            "Epoch :  56 , Avg loss :  0.5722404378166647\n",
            "Epoch :  57 , Avg loss :  0.5670551413010811\n",
            "Epoch :  58 , Avg loss :  0.5618652618122394\n",
            "Epoch :  59 , Avg loss :  0.5566702232840748\n",
            "Epoch :  60 , Avg loss :  0.5514694824711247\n",
            "Epoch :  61 , Avg loss :  0.5462625262252695\n",
            "Epoch :  62 , Avg loss :  0.5410488690340745\n",
            "Epoch :  63 , Avg loss :  0.5358280507918152\n",
            "Epoch :  64 , Avg loss :  0.5305996347778585\n",
            "Epoch :  65 , Avg loss :  0.5253632058201776\n",
            "Epoch :  66 , Avg loss :  0.5201183686244556\n",
            "Epoch :  67 , Avg loss :  0.5148647462515574\n",
            "Epoch :  68 , Avg loss :  0.5096019787281634\n",
            "Epoch :  69 , Avg loss :  0.504329721777113\n",
            "Epoch :  70 , Avg loss :  0.49904764565553833\n",
            "Epoch :  71 , Avg loss :  0.4937554340902017\n",
            "Epoch :  72 , Avg loss :  0.4884527833006239\n",
            "Epoch :  73 , Avg loss :  0.48313940110161646\n",
            "Epoch :  74 , Avg loss :  0.4778150060777316\n",
            "Epoch :  75 , Avg loss :  0.472479326822942\n",
            "Epoch :  76 , Avg loss :  0.4671321012395608\n",
            "Epoch :  77 , Avg loss :  0.46177307589103067\n",
            "Epoch :  78 , Avg loss :  0.45640200540376435\n",
            "Epoch :  79 , Avg loss :  0.45101865191369755\n",
            "Epoch :  80 , Avg loss :  0.4456227845536535\n",
            "Epoch :  81 , Avg loss :  0.44021417897799825\n",
            "Epoch :  82 , Avg loss :  0.4347926169214087\n",
            "Epoch :  83 , Avg loss :  0.4293578857888813\n",
            "Epoch :  84 , Avg loss :  0.4239097782743801\n",
            "Epoch :  85 , Avg loss :  0.41844809200576794\n",
            "Epoch :  86 , Avg loss :  0.41297262921388184\n",
            "Epoch :  87 , Avg loss :  0.40748319642381026\n",
            "Epoch :  88 , Avg loss :  0.4019796041666044\n",
            "Epoch :  89 , Avg loss :  0.3964616667098161\n",
            "Epoch :  90 , Avg loss :  0.3909292018053947\n",
            "Epoch :  91 , Avg loss :  0.3853820304536049\n",
            "Epoch :  92 , Avg loss :  0.3798199766817439\n",
            "Epoch :  93 , Avg loss :  0.37424286733653916\n",
            "Epoch :  94 , Avg loss :  0.36865053188920494\n",
            "Epoch :  95 , Avg loss :  0.36304280225221897\n",
            "Epoch :  96 , Avg loss :  0.35741951260696053\n",
            "Epoch :  97 , Avg loss :  0.3517804992414206\n",
            "Epoch :  98 , Avg loss :  0.3461256003972591\n",
            "Epoch :  99 , Avg loss :  0.3404546561255422\n",
            "Epoch :  100 , Avg loss :  0.33476750815054623\n",
            "Epoch :  101 , Avg loss :  0.3290639997410624\n",
            "Epoch :  102 , Avg loss :  0.3233439755886817\n",
            "Epoch :  103 , Avg loss :  0.3176072816925779\n",
            "Epoch :  104 , Avg loss :  0.3118537652503445\n",
            "Epoch :  105 , Avg loss :  0.30608327455447554\n",
            "Epoch :  106 , Avg loss :  0.3002956588941096\n",
            "Epoch :  107 , Avg loss :  0.29449076846168437\n",
            "Epoch :  108 , Avg loss :  0.28866845426417814\n",
            "Epoch :  109 , Avg loss :  0.2828285680386328\n",
            "Epoch :  110 , Avg loss :  0.27697096217168077\n",
            "Epoch :  111 , Avg loss :  0.27109548962281255\n",
            "Epoch :  112 , Avg loss :  0.26520200385114545\n",
            "Epoch :  113 , Avg loss :  0.259290358745466\n",
            "Epoch :  114 , Avg loss :  0.2533604085573377\n",
            "Epoch :  115 , Avg loss :  0.24741200783707865\n",
            "Epoch :  116 , Avg loss :  0.24144501137242666\n",
            "Epoch :  117 , Avg loss :  0.23545927412972295\n",
            "Epoch :  118 , Avg loss :  0.2294546511974551\n",
            "Epoch :  119 , Avg loss :  0.22343099773201158\n",
            "Epoch :  120 , Avg loss :  0.21738816890551024\n",
            "Epoch :  121 , Avg loss :  0.2113260198555702\n",
            "Epoch :  122 , Avg loss :  0.205244405636907\n",
            "Epoch :  123 , Avg loss :  0.1991431811746372\n",
            "Epoch :  124 , Avg loss :  0.19302220121918637\n",
            "Epoch :  125 , Avg loss :  0.18688132030270052\n",
            "Epoch :  126 , Avg loss :  0.1807203926968675\n",
            "Epoch :  127 , Avg loss :  0.1745392723720608\n",
            "Epoch :  128 , Avg loss :  0.1683378129577228\n",
            "Epoch :  129 , Avg loss :  0.16211586770390987\n",
            "Epoch :  130 , Avg loss :  0.15587328944392645\n",
            "Epoch :  131 , Avg loss :  0.14960993055797916\n",
            "Epoch :  132 , Avg loss :  0.14332564293778594\n",
            "Epoch :  133 , Avg loss :  0.13702027795207916\n",
            "Epoch :  134 , Avg loss :  0.13069368641294515\n",
            "Epoch :  135 , Avg loss :  0.12434571854294516\n",
            "Epoch :  136 , Avg loss :  0.11797622394296657\n",
            "Epoch :  137 , Avg loss :  0.1115850515607556\n",
            "Epoch :  138 , Avg loss :  0.105172049660085\n",
            "Epoch :  139 , Avg loss :  0.09873706579051347\n",
            "\n",
            "Original output:  5\n",
            "Predicted output:  5.399447629090172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWuYasnoThjN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}